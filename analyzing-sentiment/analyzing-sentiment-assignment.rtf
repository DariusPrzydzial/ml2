{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;\f1\fnil\fcharset0 HelveticaNeue-Medium;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red30\green87\blue232;
\red51\green51\blue51;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid201\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid13}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}}
\margl1440\margr1440\vieww15180\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl800\sa280

\f0\fs68 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Analyzing product sentiment\
\pard\pardeftab720\sl400\sa280

\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
In this module, we focused on classifiers, applying them to analyzing product sentiment, and understanding the types of errors a classifier makes. We also built an exciting IPython notebook for analyzing the sentiment of real product reviews.\
In this assignment, we are going to explore this application further, training a sentiment analysis model using a set of key polarizing words, verify the weights learned to each of these words, and compare the results of this simpler classifier with those of the one using all of the words. These techniques will be a core component in your capstone project.\
Follow the rest of the instructions on this page to complete your program. When you are done, 
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 instead of uploading your code, you will answer a series of quiz questions
\i0\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  (see the quiz after this reading) to document your completion of this assignment. The instructions will indicate what data to collect for answering the quiz.\
\pard\pardeftab720\sl480\sa280

\f1\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Learning outcomes\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\sa280
\ls1\ilvl0
\f0\fs28 \cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Execute sentiment analysis code with the IPython notebook\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Load and transform real, text data\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .apply() 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 function to create new columns (features) for our model\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compare results of two models, one using all words and the other using a subset of the words\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compare learned models with majority class prediction\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Examine the predictions of a sentiment model\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Build a sentiment analysis model using a classifier\cb1 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl480\sa280

\b\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Resources you will need
\f1\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 You will need to install the software tools or use the free Amazon EC2 machine. Instructions for both options are provided in the reading for Module 1.\
\
\pard\pardeftab720\sl480\sa280

\f1\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Download the data and starter code\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Before getting started, you will need to download the dataset and the starter IPython notebook that we used in the module.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\sa280
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Download the product review dataset here in SFrame format: {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/olwnt5xfhN_E60UGlSDndXLqeZcn0mns505E5pMnl-oEOuxHz4XomyOQtueP5a-vhhA1R8ttUZkyW2B5xgorAg.67HULGa07SrI6s0vPMGChw.BVcy9S3gRmqjgXfeELPHxZRJ3UPx09dVg28I3Jzi_EtRKofLVdBpPsQ42iEt4O4o7_hmC01U8w77kzruGCR7oNF6cCaYmeXqOHjlHfP5YEhlDbJUweAVKl7hY9lZGbN7Wdn1IXbgK7hgB5OzVmsMxipjYgV7-Jv-fsSSeMFmRAIi3nOgXbgqwp5Qbpguk_7YYO8IhXfqcS2nH0PM3V8tRuxOp7pmjSWYASdm2qgmirHfIv3EipZFfUadexlYW7UulJgsZo1_Y31VtDXIfIORbQiBYJfpyKpY0ozTKpNBmepjK-gE7d-tzAfZ-Lw_grLluD-fK0u44j6rcdRFnzLmF2AMnIyXnPuVoTmvova0wlgPOrBZnLP5sSOMN-UbELevzz-RqUA7c4YvR2yPzS1fKCPapQ1vZINk57kNLLaHa4T7n9PcGo-LnteWuTP9s6kb"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 amazon_baby.gl.zip}}\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Download the sentiment analysis notebook from the module here: {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/FJGVh7wH6rJkeIREeppIiQHVEpIxgXAP11CRnvIyRFkjavcpKc36qKzC10MCM9o5HlXuhDLKRYNb2-yOAFW4jA.PUiv-Hgqw9lLcMw8pxtxUQ.2EV1zzi74b6sdgMezX_j8vatpTIldUKPuAPxMIo5Uid6EnWC5__XnDZPAjzd-r96Se30DwQ6fJqclhzOUMtBrCqbkYEdABIXPyL4h3Q9ITLnZxIf5t4OIu5wZFqugGi3qm6oRBKXGph-fxazrRPzZS3f2wrBsnOgBDYiM6enyrRpmhrcr3O9KePCoBY0mgu2fUHrOeN8ZP_i9mRRA1fUAQ07Nb04K93CZxuwhUGAp6rhKNLABnR6LeORd1tIsjKpJrysnmQnitQM7qSnp973t-ewPOV9shiHVEE7w2XMhQRIVcokefqXNN9J6sLbBFHKw3kFc75SYN5YmVDjppX0t51DbmrCl7iLX0BW3qS1SHU__Xq2jHSA48rGeNujMLk-2bmRmtPRp0pQps1cp5mTcMzNN2QGYn6J5liwTssbJP5mfLG-eVlEXoV0LnjtrL9tlZXJrWOSazaov2YAEOdLk82eV3f0IRuJKjhzRHotAci98IBbtdLnx7fZILvOaFgr"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Analyzing product sentiment.ipynb}}\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Save both of these files in the same directory (where you are calling IPython notebook from) and unzip the data file.\cb1 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Now you are ready to get started!\
\pard\pardeftab720\sl480\sa280

\i\b\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Note: If you would rather use other ML tools...
\f1\i0\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 You are welcome to use any ML tool for this course, such as {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/2Y7tBRNZ-XZIE_flmf2D22y0TP7bQGy2XSfWrAHIa5FP_Nvjpad5MEK22S6illPLB4kKqpl4cABi31NsQxb1RA.J96O6P0OD6E5rMseU4kiag.unh04Let0NrckdHXKLCOIGZ2nUGbgauMUwOzhcaTzTcFvFpmFTj4vLHUZUNspFUCg6Peo6Hihe-vqB--gPMq664Djj0827guZhe1XGWHGgX4pNnYKvCPpIn7MDoo-_jK3d9KAk2nGdyAKBPJ4cegwsER-fpeP9j0Pw67VhONV0G7pKH-BcaOqUCShIAivHmickJsYxbzybnZx18Ts60o7XbC8Y-Dos-lWOphBcNmUNsoy3k8sW6CBfbunvuvXL5QkUiiZfmbR5WOPEyCe5t1YGsnqxV-rXk5C1qrPdA39Gk"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 scikit-learn}}. Though, as discussed in the intro module,
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0  we strongly recommend you use IPython Notebook and GraphLab Create. (GraphLab Create is free for academic purposes.)
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
If you are choosing to use other packages, we still recommend you use SFrame, which will allow you to scale to much larger datasets than Pandas. (Though, it's possible to use Pandas in this course, if your machine has sufficient memory.) The SFrame package is available in {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/s9ZenAUOnAyLhOm0psSjkFPD_PaP7j9guqOg2Hzw8XKo68JOCqcZUSxfvNHrHNnK6hHNe5yoLAsndi0N6EdWkQ.ykD3a4UxmN0Nl6NCXUN-9A.1-r84LZ9ZvCUFfPPcb-byO6jua5JylGxe5NCFKZiH3EJPf4kituI2FwrdAq-7hnJqkg2DJV81voPrqKRxC9ThO2eZEQokiW8pIErRzvBlOmxc6E8TFOa82yPXPv6gqI9XLj05GMVm0n8Jw6tDwRHi4RRkOg1H8s1i9KDEoXya9cJuVGReK-uhL6OjyGgkxas7Tr_40yDm0rzDetZ3fYfK6F81eL9Nzd9oupMX3CkayFAvb-e3fxhAHwMuvrmyuNm3hlEjdcpgndPoebu_JcGGIKitsZjE5LklpEsKFFHUvE"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 open-source under a permissive BSD license}}. So, you will always be able to use SFrames for free.\
If you are not using SFrame, here is the dataset for this assignment in CSV format, so you can use {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/unwiYVVbg7qnXtYJqvXI2wDy1-hfdn2-3WK-Ld7i7d6g9jKchLDgAuWRKRylruNHMHegaF_FfF99264Iw_7_Qg.YChQWRkQfr0DQNTgjOZwpw.yWRCiycA6p1HCj0vzaX8mxxdAFmgUQoALSlQdNjotyLSoWOnmzWHCjcZBf8ryYJ7bdw6qt9LpW5uzFIw_ig9ryIJh_4r2vocTrfs0lbbEQJPDqBsS8dQF12eL9wQfyld1N1CShYQdJ6I4Urg_5D5dwFvQKClMv5oVDcO2m9pjDl3ecqrHmsatjLjnJohaff2rBYlqt7iSHFXT3lHLf7nlOJlmc4vLoVceoO0JScmx2zqqnn3IB6U3lZL6TedDcN0ap6TRLBBfRkUrsp6NjoK_g"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Pandas}} or other options out there: {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/V5EViOzKkZWeIHVUvD01LAsY30u6jn36Ydekuv7OSXBR38q--r_MvyEkNZzZ2Un8d1EqaUPljBcbuaIoRHNi6w.qOS8Uywx3fAaOPVVRD0dSQ.PEE3Qxyp2eoLWrJ4I9hS7F7jbU6eFmelxf0JKKd9R-ffru73y2_Zaoft7lSeDwuFDkR62SKEjx4kUmWgDV7G3L0XcPDauUirr1QOjpEP_JTNVTgwOqn-e_tXWLHjAnFr4w9oRSBD840HSiG2fnwOPzlfDjTvR5_CkQIGo0BTtH9Hfzs8kXDZidkYpOEyIytb2ddKf8GRlGVLvmbzt2Ter39Zk-nOXaeUrD79E15dx0FQl3IDHNAiKmY4ulj-EPm40VnVzJIoak802cgtf8WjSqTfNaPL_YdSYuBf_3dA9hzgVh3dD4R-VrNyafcfYJiUOYJfs0ZKGDmR3AfArpt4vdQvXnZ_0MECmK1kSubhYoH6lAOOuZNYtmaDCeaRRsto"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 amazon_baby.csv}}\
\
\pard\pardeftab720\sl480\sa280

\f1\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Watch the video and explore the IPython notebook on analyzing sentiment\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 If you haven\'92t done so yet, before you start, we recommend you watch the video where we go over the IPython notebook on analyzing product sentiment using classifiers from this module. You can then open up the IPython notebook we used and familiarize yourself with the steps we covered in this example.\
\pard\pardeftab720\sl480\sa280

\f1\fs40 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 What you will do\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Now you are ready! We are going do four tasks in this assignment. There are several results you need to gather along the way to enter into the quiz after this reading.\
In the IPython notebook above, we used the word counts for all words in the reviews to train the sentiment classifier model. Now, we are going to follow a similar path, but only use this subset of the words:\
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Often, ML practitioners will throw out words they consider \'93unimportant\'94 before training their model. This procedure can often be helpful in terms of accuracy. Here, we are going to throw out all words except for the very few above. Using so few words in our model will hurt our accuracy, but help us interpret what our classifier is doing.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls3\ilvl0
\b \cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use .apply() to build a new feature with the counts for each of the selected_words:
\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  In the notebook above, we created a column \'91word_count\'92 with the word counts for each review. Our first task is to create a new column in the products SFrame with the counts for each selected_word above, and, in the process, we will see how the method .apply() can be used to create new columns in our data (our features) and how to use a Python function, which is an extremely useful concept to grasp!\cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Our first goal is to create a column 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 products[\'91awesome\'92]
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  where each row contains the number of times the word 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 showed up in the review for the corresponding product, and 0 if the review didn\'92t show up. One way to do this is to look at the each row 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91word_count\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  column and follow this logic:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls4\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 If 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  shows up in the word counts for a particular product (row of the products SFrame), then we know how often 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  appeared in the review,\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 if 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  doesn\'92t appear in the word counts, then it didn\'92t appear in the review, and we should set the count for 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  to 0 in this review.\cb1 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 We could use a for loop to iterate this logic for each row of the products SFrame, but this approach would be really slow, because the SFrame is not optimized for this being accessed with a for loop. Instead, we will use the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .apply() 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 method to iterate the the logic above for each row of the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 products[\'91word_count\'92] 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 column (which, since it\'92s a single column, has type SArray). {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/OPcZkHMwKXJvlBTDbRGoO0kvkxn7tzdt0uUpFRx7XnnXvdDQB2irofRJ__n6bfOx9_MPLZpMMGfISQpFAkQyzw.0Wfl9pEV0ipgiAkBDe7HoQ.0xmSPP6tqm4wnPLFxP-Pwg7SF6rLPz46QxGWPwMEjjgZaJjb5JTAzJFIgZWS9jSxjGHbD4PM4yVz2il0dZwq-weaWOeq-Ou-3xA9ktuVzhJ3_62DRaIAtyqdG70xLxhp2y8sH3oMTq-1Ciqh4nn_Y6wAJ8ulYI8ymI1ERMKrdTEAu7qMmFNhxBgg3bjDi4M2V0y5lTy_dXu7Ue3FREJHtTAnMhWDtCia9MDzvvRVWy8B-4mV7lKOAAD8Yn890n3_FQEsFiAzNa1V3GgBr51paMz1Fz2FsQmIn2WlbTWwA_FxqIxNGQrkJE940KZZl6wG946thzfsfp1SVo4FLodmn23-F-wPrNrTxl2X4D5DzWcmyq8Wu9z7eNQNIsyC40a2DGgU1I3njGozT7s7Gviq-g"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Read about using the .apply() method on an SArray here.}}\
We are now ready to create our new columns:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls6\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 First, you will use a Python function to define the logic above. You will write a function called
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 awesome_count
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  which takes in the word counts and returns the number of times 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 appears in the reviews.\cb1 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 A few tips:\
i. Each entry of the \'91word_count\'92 column is of {\field{\*\fldinst{HYPERLINK "https://eventing.coursera.org/api/redirectStrict/LG0mNEdE1I6yqatuPIOCisNDDx2wk6DuDY39JnIq34uG2KY4fKhujzW1Cp3SNQDK0AVId2VSIsmiCsJYcXdZpg.mDLW3DatcICzdWgGq9MxuA.uR-mtofyUuJDf1IkYilW17HDGz7qeAwMBqEndnIQZHTxuJ01_o_CpPu2N66K7LhSYXv5XUwVHXz0RfxvETqnBZTWOBczoMBJjNmHadlEsia7NELZx6sfkn1rX1XJfe_F8rw4wqV6VHEM_w34kJIh_xEAGLuX3sJd5Uk6usJ8LdFrbgoNip77tzfTrIhEXyCtasJZm2ghzd--sJb4jMpXSPzfr5yV-SskG1XynM0_3q-kdnKkN7ExcAGazrDZfTQCe1dN7tt-j4LLXPhWCv1RAEXB74dTXYBjbEWA4BkMtIYRigxZoUUtqhZmGNH5-ex4zDlUYayOMwtxtxbaRbiTRGtScHzOJFTkTc2NjVYZcOC7lQGgvibyhpkJstOABK7T"}}{\fldrslt \cf4 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Python type dictionary}}.\
ii. If you have a dictionary called 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 dict
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 , you can access a field in the dictionary using:\
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 dict[\'91awesome\'92]\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 but only if 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  is one of the fields in the dictionary, otherwise you will get a nasty error.\
iii. In Python, to test if a dictionary has a particular field, you can simply write:\
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 if \'91awesome\'92 in dict\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In our case, if this condition doesn\'92t hold, the count of 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 should be 0.\
Using these tips, you can now write the awesome_count function.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls7\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Next, you will use 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .apply()
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  to iterate 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 awesome_count
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  for each row of 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 products[\'91word_count\'92] 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 and create a new column called 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91awesome\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  with the resulting counts. Here is what that looks like:\cb1 \
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 products[\'91awesome\'92] = products[\'91word_count\'92].apply(awesome_count)\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 And you are done! Check the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 products
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  SFrame and you should see the new column you just create.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\sa280
\ls8\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Repeat this process for the other 11 words in 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . (Here, we described a simple procedure to obtain the counts for each 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_word
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . There are other more efficient ways of doing this, and we encourage you to explore this further.)\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls8\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .sum() 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 method on each of the new columns you created, answer the following questions: Out of the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 , which one is most used in the dataset? Which one is least used? 
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Save these results to answer the quiz at the end.
\i0\b0 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl400\sa280
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 2. 
\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Create a new sentiment analysis model using only the selected_words as features:
\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  In the IPython Notebook above, we used word counts for all words as features for our sentiment classifier. Now, you are just going to use the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 :\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls9\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the same train/test split as in the IPython Notebook from lecture:\cb1 \
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 train_data,test_data = products.random_split(.8, seed=0)\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls10\ilvl0
\f0\fs28 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Train a logistic regression classifier (use 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 graphlab.logistic_classifier.create
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 ) using just the
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0  selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . Hint: you can use this parameter in the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .create()
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  call to specify the features used to be exactly the new columns you just created:\cb1 \
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 features=selected_words\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Call your new model: 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words_model
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls11\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 You will now examine the weights the learned classifier assigned to each of the 11 words in
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  and gain intuition as to what the ML algorithm did for your data using these features. In GraphLab Create, a learned model, such as the selected_words_model, has a field 'coefficients', which lets you look at the learned coefficients. You can access it by using:\cb1 \
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 selected_words_model[\'91coefficients\'92]\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The result has a column called \'91value\'92, which contains the weight learned for each feature.\
Using this approach, sort the learned coefficients according to the \'91value\'92 column using 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .sort()
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . Out of the 11 words in 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 , which one got the most positive weight? Which one got the most negative weight? Do these values make sense for you? 
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Save these results to answer the quiz at the end.
\i0\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
3. 
\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Comparing the accuracy of different sentiment analysis model: 
\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Using the method\
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 .evaluate(test_data)\
\pard\pardeftab720\sl400\sa280

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 What is the accuracy of the
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0  selected_words_model
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  on the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 test_data
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 ? What was the accuracy of the
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 sentiment_model
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  that we learned using all the word counts in the IPython Notebook above from the lectures? What is the accuracy 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 majority
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  class classifier on this task? How do you compare the different learned models with the baseline approach where we are just predicting the majority class? 
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Save these results to answer the quiz at the end.
\i0\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl400\sa280

\i \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Hint: we discussed the majority class classifier in lecture, which simply predicts that every data point is from the most common class. This is baseline is something we definitely want to beat with models we learn from data.
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
4. 
\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Interpreting the difference in performance between the models: 
\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 To understand why the model with all word counts performs better than the one with only the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 , we will now examine the reviews for a particular product.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\sa280
\ls12\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We will investigate a product named 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91Baby Trend Diaper Champ\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . (This is a trash can for soiled baby diapers, which keeps the smell contained.)\cb1 \
\ls12\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Just like we did for the reviews for the giraffe toy in the IPython Notebook in the lecture video, before we start our analysis you should select all reviews where the product name is 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91Baby Trend Diaper Champ\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 . Let\'92s call this table 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 diaper_champ_reviews
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .\cb1 \
\ls12\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Again, just as in the video, use the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 sentiment_model 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 to predict the sentiment of each review in
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 diaper_champ_reviews
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  and sort the results according to their 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91predicted_sentiment\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 .\cb1 \
\ls12\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 What is the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91predicted_sentiment\'92
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  for the most positive review for 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \'91Baby Trend Diaper Champ\'92 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 according to the sentiment_model from the IPython Notebook from lecture? 
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Save this result to answer the quiz at the end.
\i0\b0 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Now use the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words_model 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 you learned using just the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words 
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 to predict the sentiment most positive review you found above. 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Hint: if you sorted the diaper_champ_reviews in descending order (from most positive to most negative), this command will be helpful to make the prediction you need:
\i0 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\pardeftab720\sl360

\f2\fs26 \cf3 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 selected_words_model.predict(diaper_champ_reviews[0:1], output_type='probability')\
\pard\pardeftab720\sl400\sa280

\f0\i\b\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Save this result to answer the quiz at the end.
\i0\b0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400
\ls13\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Why is the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 predicted_sentiment
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  for the most positive review found using the model with all word counts (
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 sentiment_model
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 ) much more positive than the one using only the 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 selected_words (selected_words_model)
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 ? 
\i \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Hint: examine the text of this review, the extracted word counts for all words, and the word counts for each of the selected_words, and you will see what each model used to make its prediction.
\i0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0  
\i\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 Save this result to answer the quiz at the end.
\i0\b0 \cb1 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \
}